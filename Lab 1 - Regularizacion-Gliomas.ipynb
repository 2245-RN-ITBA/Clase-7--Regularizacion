{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radiomics\n",
    "\n",
    "La radiómica es un campo de estudio médico que busca extraer características cuantitativas de imágenes médicas, convirtiendo las imágenes en datos minables y aplicando el análisis de estos datos para brindar soporte a la decisión clínica. De la misma forma que la genómica o la proteómica, este campo de la medicina de precisión busca encontrar patrones explicativos en sets de gran cantidad de datos. Se contrapone a la práctica tradicional de tratar las imágenes médicas como meras imágenes demostrativas destinadas únicamente a interpretación visual. La radiómica contiene estadística de primer, segundo y alto orden, que combinados con datos clínicos del paciente pueden generar modelos que potencialmente podrían mejorar la precisión diagnóstica, prognóstico y predictiva. \n",
    "\n",
    "La radiómica ha demostrado un buen desempeño en otros tipos de cáncer, especialmente de cerebro y de próstata, ya que son patologías de alta prevalencia y para las que se cuenta con sets de imágenes de gran tamaño. El pipeline de radiomics consiste en la adquisición de imagen, la segmentación de la región de interés, un posible preprocesamiento de la imagen (filtrado, resampleo, padding, cropping, entr otros) y finalmente la extracción de los \"radiomic features\". Para Python existe el paquete [pyradiomics](https://pyradiomics.readthedocs.io/en/latest/customization.html) que explica cómo configurar este proceso en su documentación.\n",
    " \n",
    "<img src=\"radiomics.jpg\" alt=\"Drawing\" style=\"width:40%;\"/>\n",
    "\n",
    "\n",
    "## Dataset de Gliomas \n",
    "\n",
    "El dataset [TCGA-LGG](https://wiki.cancerimagingarchive.net/display/Public/TCGA-LGG#49dd0de7af2043e680c4ecb36fe605a3) es un dataset público que combina información genética del Cancer Genome Archive (TCGA) con imágenes de resonancia magnética de cerebro del Cancer Imaging Archive (TCIA) , pertenecientes a pacientes diagnosticados con glioma de bajo grado (Low Grade Glioma). Este tipo de tumor puede estar asociado a una mutación genética, en cuyo caso el tratamiento será diferente. Es de interés poder predecir esta mutación ya que el análisis genómico es muy costoso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/rn-2019-itba/Clase-7--Regularizacion/master/radiomics_gliomas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_firstorder_10Percentile</th>\n",
       "      <th>original_firstorder_90Percentile</th>\n",
       "      <th>original_firstorder_Energy</th>\n",
       "      <th>original_firstorder_Entropy</th>\n",
       "      <th>original_firstorder_InterquartileRange</th>\n",
       "      <th>original_firstorder_Kurtosis</th>\n",
       "      <th>original_firstorder_Maximum</th>\n",
       "      <th>original_firstorder_Mean</th>\n",
       "      <th>original_firstorder_MeanAbsoluteDeviation</th>\n",
       "      <th>original_firstorder_Median</th>\n",
       "      <th>...</th>\n",
       "      <th>wavelet-LLH_firstorder_Uniformity</th>\n",
       "      <th>wavelet-LLH_firstorder_Variance</th>\n",
       "      <th>wavelet-LLH_glcm_Autocorrelation</th>\n",
       "      <th>wavelet-LLH_glcm_ClusterProminence</th>\n",
       "      <th>wavelet-LLH_glcm_ClusterShade</th>\n",
       "      <th>wavelet-LLH_glcm_ClusterTendency</th>\n",
       "      <th>wavelet-LLH_glcm_Contrast</th>\n",
       "      <th>wavelet-LLH_glcm_Correlation</th>\n",
       "      <th>wavelet-LLH_glcm_DifferenceAverage</th>\n",
       "      <th>Mutacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>155.615205</td>\n",
       "      <td>353.184777</td>\n",
       "      <td>2.878215e+08</td>\n",
       "      <td>5.809761</td>\n",
       "      <td>97.306704</td>\n",
       "      <td>2.834441</td>\n",
       "      <td>434.351234</td>\n",
       "      <td>266.625929</td>\n",
       "      <td>60.124082</td>\n",
       "      <td>277.726650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041838</td>\n",
       "      <td>1257.667670</td>\n",
       "      <td>644.310749</td>\n",
       "      <td>58710.668931</td>\n",
       "      <td>-51.434398</td>\n",
       "      <td>128.596721</td>\n",
       "      <td>69.240755</td>\n",
       "      <td>0.301791</td>\n",
       "      <td>6.214115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191.101389</td>\n",
       "      <td>372.599007</td>\n",
       "      <td>2.066994e+09</td>\n",
       "      <td>5.637016</td>\n",
       "      <td>99.693104</td>\n",
       "      <td>2.549367</td>\n",
       "      <td>424.250372</td>\n",
       "      <td>293.920752</td>\n",
       "      <td>55.622405</td>\n",
       "      <td>306.916096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110662</td>\n",
       "      <td>212.043507</td>\n",
       "      <td>162.874178</td>\n",
       "      <td>3080.122135</td>\n",
       "      <td>-96.878003</td>\n",
       "      <td>27.905486</td>\n",
       "      <td>5.517043</td>\n",
       "      <td>0.668519</td>\n",
       "      <td>1.679473</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.543544</td>\n",
       "      <td>413.165807</td>\n",
       "      <td>1.496800e+08</td>\n",
       "      <td>5.860199</td>\n",
       "      <td>103.001719</td>\n",
       "      <td>2.833426</td>\n",
       "      <td>475.078627</td>\n",
       "      <td>261.387435</td>\n",
       "      <td>70.544241</td>\n",
       "      <td>246.738413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045860</td>\n",
       "      <td>1237.007712</td>\n",
       "      <td>492.419360</td>\n",
       "      <td>69561.725366</td>\n",
       "      <td>-959.722953</td>\n",
       "      <td>162.728062</td>\n",
       "      <td>60.573934</td>\n",
       "      <td>0.468938</td>\n",
       "      <td>5.976991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>247.658193</td>\n",
       "      <td>420.426441</td>\n",
       "      <td>2.117501e+08</td>\n",
       "      <td>5.607336</td>\n",
       "      <td>113.453612</td>\n",
       "      <td>2.119373</td>\n",
       "      <td>474.868965</td>\n",
       "      <td>335.706343</td>\n",
       "      <td>58.695066</td>\n",
       "      <td>337.126368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072517</td>\n",
       "      <td>613.130293</td>\n",
       "      <td>696.942500</td>\n",
       "      <td>15338.156162</td>\n",
       "      <td>-432.844674</td>\n",
       "      <td>52.406665</td>\n",
       "      <td>21.422252</td>\n",
       "      <td>0.386653</td>\n",
       "      <td>3.373647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191.321605</td>\n",
       "      <td>404.324298</td>\n",
       "      <td>5.687897e+08</td>\n",
       "      <td>5.871768</td>\n",
       "      <td>96.504857</td>\n",
       "      <td>3.300441</td>\n",
       "      <td>476.342717</td>\n",
       "      <td>314.116180</td>\n",
       "      <td>62.270515</td>\n",
       "      <td>328.312934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057828</td>\n",
       "      <td>724.368720</td>\n",
       "      <td>857.655164</td>\n",
       "      <td>24572.757630</td>\n",
       "      <td>-132.585964</td>\n",
       "      <td>73.449313</td>\n",
       "      <td>50.763610</td>\n",
       "      <td>0.190613</td>\n",
       "      <td>5.220063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 642 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_firstorder_10Percentile  original_firstorder_90Percentile  \\\n",
       "0                        155.615205                        353.184777   \n",
       "1                        191.101389                        372.599007   \n",
       "2                        162.543544                        413.165807   \n",
       "3                        247.658193                        420.426441   \n",
       "4                        191.321605                        404.324298   \n",
       "\n",
       "   original_firstorder_Energy  original_firstorder_Entropy  \\\n",
       "0                2.878215e+08                     5.809761   \n",
       "1                2.066994e+09                     5.637016   \n",
       "2                1.496800e+08                     5.860199   \n",
       "3                2.117501e+08                     5.607336   \n",
       "4                5.687897e+08                     5.871768   \n",
       "\n",
       "   original_firstorder_InterquartileRange  original_firstorder_Kurtosis  \\\n",
       "0                               97.306704                      2.834441   \n",
       "1                               99.693104                      2.549367   \n",
       "2                              103.001719                      2.833426   \n",
       "3                              113.453612                      2.119373   \n",
       "4                               96.504857                      3.300441   \n",
       "\n",
       "   original_firstorder_Maximum  original_firstorder_Mean  \\\n",
       "0                   434.351234                266.625929   \n",
       "1                   424.250372                293.920752   \n",
       "2                   475.078627                261.387435   \n",
       "3                   474.868965                335.706343   \n",
       "4                   476.342717                314.116180   \n",
       "\n",
       "   original_firstorder_MeanAbsoluteDeviation  original_firstorder_Median  \\\n",
       "0                                  60.124082                  277.726650   \n",
       "1                                  55.622405                  306.916096   \n",
       "2                                  70.544241                  246.738413   \n",
       "3                                  58.695066                  337.126368   \n",
       "4                                  62.270515                  328.312934   \n",
       "\n",
       "     ...     wavelet-LLH_firstorder_Uniformity  \\\n",
       "0    ...                              0.041838   \n",
       "1    ...                              0.110662   \n",
       "2    ...                              0.045860   \n",
       "3    ...                              0.072517   \n",
       "4    ...                              0.057828   \n",
       "\n",
       "   wavelet-LLH_firstorder_Variance  wavelet-LLH_glcm_Autocorrelation  \\\n",
       "0                      1257.667670                        644.310749   \n",
       "1                       212.043507                        162.874178   \n",
       "2                      1237.007712                        492.419360   \n",
       "3                       613.130293                        696.942500   \n",
       "4                       724.368720                        857.655164   \n",
       "\n",
       "   wavelet-LLH_glcm_ClusterProminence  wavelet-LLH_glcm_ClusterShade  \\\n",
       "0                        58710.668931                     -51.434398   \n",
       "1                         3080.122135                     -96.878003   \n",
       "2                        69561.725366                    -959.722953   \n",
       "3                        15338.156162                    -432.844674   \n",
       "4                        24572.757630                    -132.585964   \n",
       "\n",
       "   wavelet-LLH_glcm_ClusterTendency  wavelet-LLH_glcm_Contrast  \\\n",
       "0                        128.596721                  69.240755   \n",
       "1                         27.905486                   5.517043   \n",
       "2                        162.728062                  60.573934   \n",
       "3                         52.406665                  21.422252   \n",
       "4                         73.449313                  50.763610   \n",
       "\n",
       "   wavelet-LLH_glcm_Correlation  wavelet-LLH_glcm_DifferenceAverage  Mutacion  \n",
       "0                      0.301791                            6.214115         1  \n",
       "1                      0.668519                            1.679473         1  \n",
       "2                      0.468938                            5.976991         1  \n",
       "3                      0.386653                            3.373647         1  \n",
       "4                      0.190613                            5.220063         0  \n",
       "\n",
       "[5 rows x 642 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 640)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "X = data[data.columns[:-2]].values\n",
    "print(X.shape)\n",
    "         \n",
    "Y = data['Mutacion'].values\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que tenemos pocas observaciones para la cantidad de variables, vamos a aplicar cross validation para hacer el 'tuning' de hiperparámetros al entrenar. La metodología es la siguiente: por cada variante de modelo que deseamos evaluar, hacemos un 'fit' para todos los 'folds' menos uno (folds de entrenamiento), y un 'predict' para el fold restante (fold de validación). Repetimos esto para todas las combinaciones de folds disponibles. Finalmente, consideramos el desempeño de validación de ese modelo como el promedio de los scores obtenidos en todas nuestras corridas de fit-predict. \n",
    "\n",
    "Por ejemplo: queremos comparar un ModeloA (con una cierta combinación de hiperparámetros), con el ModeloB (otra combinación diferente), y haciendo un cross-validation de 3 folds, es decir, dividiendo nuestro dataset en tres: fold1, fold2, fold3.\n",
    "\n",
    "1) Nuevo ModeloA. Fit de ModeloA con fold1+fold2\n",
    "\n",
    "2) Predict de ModeloA ajustado en (1) sobre fold3 --> \"score1\"\n",
    "\n",
    "3) Nuevo ModeloA. Fit de ModeloA con fold1+fold3\n",
    "\n",
    "4) Predict de ModeloA ajustado en (3) sobre fold2 --> \"score2\"\n",
    "\n",
    "5) Nuevo ModeloA. Fit de ModeloA con fold2+fold3\n",
    "\n",
    "6) Predict de ModeloA ajustado en (5) sobre fold1 --> \"score3\"\n",
    "\n",
    "7) ScoreA será el promedio de score1, score2 y score3.\n",
    "\n",
    "Repetimos los pasos para ModeloB, y obtenemos el ScoreB. La comparación entre ScoreA y ScoreB nos definirá qué combinación de hiperparámetros es mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(10) #10 folds\n",
    "splited_indexs = skf.split(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos nuestros folds de cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV dataset: 1\n",
      "(134,) (16,)\n",
      "CV dataset: 2\n",
      "(134,) (16,)\n",
      "CV dataset: 3\n",
      "(134,) (16,)\n",
      "CV dataset: 4\n",
      "(134,) (16,)\n",
      "CV dataset: 5\n",
      "(135,) (15,)\n",
      "CV dataset: 6\n",
      "(135,) (15,)\n",
      "CV dataset: 7\n",
      "(136,) (14,)\n",
      "CV dataset: 8\n",
      "(136,) (14,)\n",
      "CV dataset: 9\n",
      "(136,) (14,)\n",
      "CV dataset: 10\n",
      "(136,) (14,)\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "training_sets = []\n",
    "for train_index, test_index in splited_indexs:\n",
    "    i=i+1\n",
    "    print(\"CV dataset:\", i)\n",
    "    print(train_index.shape, test_index.shape)\n",
    "    dictionary = {'X_train':X[train_index], 'y_train':Y[train_index], 'X_test':X[test_index],'y_test':Y[test_index]}\n",
    "    training_sets.append(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método cross_validate ejecuta el proceso descripto anteriormente. Debemos especificar el modelo que queremos ajustar ('estimator'), nuestros datos de entrada ('X'), nuestros targets ('y'), y un objeto de cross-validation ('cv'. Ver documentación, este objeto soporta también otros formatos)\n",
    "\n",
    "Por ejemplo, comencemos evaluando un modelo Lasso con hiperparámetro lambda de 0.5 (Recordar que en sklearn este hiperpárametro es llamado alpha). Como score utilizaremos error cuadrático medio. (¿Por qué no podemos usar Accuracy?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UsuarioHI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\UsuarioHI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\UsuarioHI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\UsuarioHI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\UsuarioHI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\UsuarioHI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\UsuarioHI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\UsuarioHI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\UsuarioHI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.51491031e+03 -1.21446419e+00 -5.73364017e-01 -5.51777575e+01\n",
      " -1.94515317e-01 -6.29410546e+03 -2.74221938e+00 -1.45447285e+04\n",
      " -3.22863156e+02 -3.06213008e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UsuarioHI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "alfa = 0.5\n",
    "clf_lasso_A = Lasso(alpha=alfa, max_iter=1e5)\n",
    "cross_val_outputs_A = cross_validate(estimator=clf_lasso_A, X=X, y=np.array(Y), cv=skf, scoring='neg_mean_squared_error')\n",
    "print('Error en cada fold:',  cross_val_outputs_A['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error A: -2273.681594647875\n"
     ]
    }
   ],
   "source": [
    "scoreA = np.mean(cross_val_outputs_A['test_score'])\n",
    "print('Score A:', scoreA)\n",
    "print('Error cuadratico medio A:', abs(scoreA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UsuarioHI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\UsuarioHI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\UsuarioHI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\UsuarioHI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\UsuarioHI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\UsuarioHI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\UsuarioHI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\UsuarioHI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\UsuarioHI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.94996606e+03 -8.66179587e+00 -1.39161740e+00 -1.82763141e+01\n",
      " -1.63359687e-01 -6.70377671e+04 -2.27517543e+00 -5.85954353e+03\n",
      " -2.37786751e+00 -5.56209590e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UsuarioHI\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "alfa = 0.1\n",
    "clf_lasso_B = Lasso(alpha=alfa, max_iter=1e5)\n",
    "cross_val_outputs_B = cross_validate(estimator=clf_lasso_B, X=X, y=np.array(Y), cv=skf, scoring='neg_mean_squared_error')\n",
    "print('Error en cada fold:', cross_val_outputs_B['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score B: -7943.663244697639\n",
      "Error cuadratico medio B: 7943.663244697639\n"
     ]
    }
   ],
   "source": [
    "scoreB = np.mean(cross_val_outputs_B['test_score'])\n",
    "print('Score B:', scoreB)\n",
    "print('Error cuadratico medio B:', abs(scoreB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en este caso obtenemos mejor Score con el primer modelo. (Igualmente parece un score muy malo)???\n",
    "\n",
    "**Red neuronal**\n",
    "\n",
    "Desarrollá una red neuronal para predecir si un glioma cerebral presenta o no mutación genética a partir de las características radiómicas de nuestro dataframe. Probá variar los distintos hiperparámetros propios de una red neuronal densa: \n",
    "\n",
    "- Cantidad de capas ocultas y cantidad de unidades por capa\n",
    "\n",
    "- Capas con dropout y su dropout rate (p)\n",
    "\n",
    "- Capas con Kernel_normalizer con L1 o L2\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-52968a39d9a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "lr=0.01\n",
    "input_shape = X.shape[1]\n",
    "hidden_units=32\n",
    "output_size=2\n",
    "\n",
    "model = Sequential()\n",
    "sgd = optimizers.SGD(lr=lr)\n",
    "model.add(Dense(hidden_units,input_dim=input_shape,  activation='relu'))\n",
    "model.add(Dense(output_size, \n",
    "                activation='sigmoid', \n",
    "                kernel_initializer='zeros', \n",
    "                name='Salida'\n",
    "               ))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X,Y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 640)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
